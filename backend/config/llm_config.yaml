# LLM Configuration File
# Enterprise-grade multi-model configuration with fallback support

# Router Configuration
router:
  fallback_enabled: true          # Enable automatic fallback on failure
  retry_times: 2                  # Number of retries before fallback
  timeout: 60                     # Request timeout in seconds
  health_check_interval: 300      # Health check interval (5 minutes)

# Model Configurations (Priority: lower number = higher priority)
models:
  # Primary Model: Qwen3-Max (Alibaba)
  - name: "qwen3-max"
    adapter_type: "qwen"
    priority: 1
    enabled: true
    api_key: "${QWEN_API_KEY}"     # Set via environment variable
    base_url: "https://dashscope.aliyuncs.com/api/v1"
    model_id: "qwen-max-latest"
    max_tokens: 4000
    temperature: 0.7
    timeout: 60
    cost_per_1k_tokens: 0.02       # RMB per 1000 tokens

  # Backup Model: DeepSeek-V3
  - name: "deepseek-v3"
    adapter_type: "deepseek"
    priority: 2
    enabled: true
    api_key: "${DEEPSEEK_API_KEY}"
    base_url: "https://api.deepseek.com/v1"
    model_id: "deepseek-chat"
    max_tokens: 4000
    temperature: 0.7
    timeout: 60
    cost_per_1k_tokens: 0.001

  # Optional Models (Disabled by default)
  # Uncomment and configure to enable

  # - name: "gpt-5.2"
  #   adapter_type: "openai"
  #   priority: 3
  #   enabled: false
  #   api_key: "${OPENAI_API_KEY}"
  #   base_url: "https://api.openai.com/v1"
  #   model_id: "gpt-5.2-turbo"
  #   max_tokens: 4000
  #   temperature: 0.7
  #   timeout: 60
  #   cost_per_1k_tokens: 0.03

  # - name: "claude-sonnet-4.5"
  #   adapter_type: "anthropic"
  #   priority: 4
  #   enabled: false
  #   api_key: "${ANTHROPIC_API_KEY}"
  #   base_url: "https://api.anthropic.com/v1"
  #   model_id: "claude-sonnet-4.5-20250929"
  #   max_tokens: 4000
  #   temperature: 0.7
  #   timeout: 60
  #   cost_per_1k_tokens: 0.03

# RAG Configuration
rag:
  enabled: true                   # Enable knowledge base retrieval
  top_k: 5                        # Number of documents to retrieve
  min_score: 0.3                  # Minimum relevance score
  use_rerank: true                # Use BM25 reranking

# Context Management
context:
  max_history: 10                 # Maximum conversation rounds to keep
  max_tokens: 8000                # Maximum context tokens
  system_prompt: |
    你是一个专业的面试助手，基于知识库回答用户关于面试的问题。

    【回答要求】
    1. 基于知识库内容回答，确保准确性
    2. 如果知识库没有相关信息，基于通用知识回答，并说明"这不在我的知识库中"
    3. 回答要结构清晰，使用Markdown格式
    4. 对于技术问题，提供代码示例
    5. 对于面试题，提供答题思路和关键点
    6. 语气专业、友好

# Rate Limiting (TODO: Implement in future version)
# rate_limit:
#   enabled: true
#   requests_per_minute: 20
#   requests_per_day: 500

# Monitoring (TODO: Implement in future version)
# monitoring:
#   enabled: true
#   log_level: "INFO"
#   metrics_enabled: true

# API Gateway (TODO: Implement in future version)
# gateway:
#   enabled: false
#   auth_enabled: false
#   cors_origins: ["*"]
